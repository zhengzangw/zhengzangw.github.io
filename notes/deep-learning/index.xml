<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>[A] æ·±åº¦å­¦ä¹  Deep Learning on Zangwei</title>
    <link>https://zhengzangw.com/notes/deep-learning/</link>
    <description>Recent content in [A] æ·±åº¦å­¦ä¹  Deep Learning on Zangwei</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>zzw at smail.nju.edu.cn (Zangwei Zheng)</managingEditor>
    <webMaster>zzw at smail.nju.edu.cn (Zangwei Zheng)</webMaster>
    <lastBuildDate>Wed, 16 Jan 2019 00:00:00 +0000</lastBuildDate><atom:link href="https://zhengzangw.com/notes/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>1-Perceptron</title>
      <link>https://zhengzangw.com/notes/deep-learning/1-perceptron/</link>
      <pubDate>Sun, 14 Apr 2019 00:00:00 +0000</pubDate>
      <author>zzw at smail.nju.edu.cn (Zangwei Zheng)</author>
      <guid>https://zhengzangw.com/notes/deep-learning/1-perceptron/</guid>
      <description>Perceptron 1957
 æ¨¡å‹ï¼š$\hat y=\text{sgn}(\omega^\top x)$ å‚æ•°å­¦ä¹ ï¼šé”™è¯¯é©±åŠ¨åœ¨çº¿å­¦ä¹ ç®—æ³•  $\omega\leftarrow 0$ å¯¹äº $y\omega^\top x&amp;lt;0,\omega\leftarrow \omega+yx$ $L(\omega;x,y)=\max(0,-y\omega^\top x)$   æ„ŸçŸ¥æœºæ”¶æ•›æ€§ï¼š$\mathcal{D}={(\mathbf{x}^{(n)},y^{(n)})}_{n=1}^N,R=\max_n|x^{(n)}|$ï¼Œè‹¥ $\mathcal{D}$ å¯åˆ†ï¼Œåˆ™ä¸¤ç±»æ„ŸçŸ¥æœºæƒé‡æ›´æ–°ä¸è¶…è¿‡ $\frac{R^2}{\gamma^2}$  ç¥ç»å…ƒ  ç¥ç»å…ƒ  å‡€è¾“å…¥ï¼š$z=\omega^\top x+b$ æ´»æ€§å€¼ï¼š$a=f(z)$ æ¿€æ´»å‡½æ•°ï¼š$f$    æ¿€æ´»å‡½æ•°  Sigmoid å‹å‡½æ•°ï¼šä¸¤ç«¯é¥±å’Œå‡½æ•°  Logistic: $\sigma(x)=\frac{1}{1+\exp(-x)}$ Tanh: $\tanh(x)=2\sigma(2x)-1=\frac{\exp(x)-\exp(-x)}{\exp(x)+\exp(-x)}$ è®¡ç®—å¼€é”€è¾ƒå¤§   hard-logistic$(x)=\max(\min(0.25x+0.5,1),0)$ hard-Tanh$(x)=\max(\min(x,1),-1)$ ReLU$(x)=\max(0,x)$  è®¡ç®—é«˜æ•ˆ ç”Ÿç‰©å­¦åˆç†æ€§ï¼šå•ä¾§æŠ‘åˆ¶ã€å®½å…´å¥‹è¾¹ç•Œ éé›¶ä¸­å¿ƒåŒ–ï¼šåç½®åç§» æ­»äº¡ ReLU é—®é¢˜   LeakyReLU$(x)=\max(x,\gamma x)$ å¸¦å‚æ•° ReLUï¼Œå¯¹äºç¬¬ $i$ ä¸ªç¥ç»å…ƒï¼šPReLU$_i(x)=\max(0,x)+\gamma_i\min(0,x)$ Exponential Linear Unit: ELU$(x)=\max(0,x)+\min(0,\gamma(\exp(x)-1))$  è¿‘ä¼¼é›¶ä¸­å¿ƒåŒ–   Softplus$(x)=\log(1+\exp(x))$ Swish$(x)=x\sigma(\beta x)$ GELU$(x)=xP(X\leq x),P(X\leq x)$ ä¸ºé«˜æ–¯ç´¯ç§¯åˆ†å¸ƒå‡½æ•° Maxout$(x)=\max_{k\in[1,K]}(z_k),z_k=\omega_k^\top x+b_k$  è¾“å…¥ä¸ºå‘é‡    </description>
    </item>
    
    <item>
      <title>2-FNN</title>
      <link>https://zhengzangw.com/notes/deep-learning/2-fnn/</link>
      <pubDate>Sun, 14 Jun 2020 00:00:00 +0000</pubDate>
      <author>zzw at smail.nju.edu.cn (Zangwei Zheng)</author>
      <guid>https://zhengzangw.com/notes/deep-learning/2-fnn/</guid>
      <description>FNN  å‰å‘ç¥ç»ç½‘ç»œ/å…¨è¿æ¥ç¥ç»ç½‘ç»œ/å¤šå±‚æ„ŸçŸ¥æœº å‰å‘ä¼ æ’­  $z^{(l)}=W^{(l)}a^{(l-1)}+b^{(l)}$ $a^{(l)}=f_l(z^{(l)})$   é€šç”¨è¿‘ä¼¼å®šç†ï¼ˆUniversal Approximation Theorem,1989)  $\phi(\cdot)$ æ˜¯ä¸€ä¸ªéå¸¸æ•°ã€æœ‰ç•Œã€å•è°ƒé€’å¢çš„è¿ç»­å‡½æ•°ï¼Œ$J_D$ æ˜¯ä¸€ä¸ª $D$ ç»´çš„å•ä½è¶…ç«‹æ–¹ä½“ $[0,1]^D$ï¼Œ$C(J_D)$ æ˜¯å®šä¹‰åœ¨ $J_D$ ä¸Šçš„è¿ç»­å‡½æ•°é›†åˆ $\forall f\in C(J_D),\exists M\in\mathbb{Z},v_m,b_m\in\mathbb{R},\omega_m\in\mathbb{R}^D$, æœ‰å‡½æ•° $F(x)=\sum_{m=1}^Mv_m\phi(\omega_m^\top x+b_m)$ $|F(x)-f(x)|&amp;lt;\epsilon,\forall x\in J_D,\epsilon$ ä¸ºå¾ˆå°æ­£æ•° åœ¨ $\mathbb{R}^D$ æœ‰ç•Œé—­é›†ä¸Šä¾ç„¶æˆç«‹   $ğ•€_i(t)$: ç¬¬ $i$ ä¸ªå…ƒç´ ä¸º $t$ å…¶ä½™ä¸º $0$ çš„è¡Œå‘é‡ åå‘ä¼ æ’­ç®—æ³•  $\delta_i^{(l)}=\frac{\partial L}{\partial z^{(l)}}=\frac{\partial L}{\partial z^{(l+1)}}\frac{\partial z^{(l+1)}}{\partial a^{(l)}}\frac{\partial a^{(l)}}{\partial z^{(l)}}=\delta_{i+1}(W^{l+1})^\top\text{diag}(f&#39;(z^{(l)}))\in\mathbb{R}^{M_l}$ $dL=\text{tr}(\frac{\partial L}{\partial z^{(l)}}dz^{(l)})=\text{tr}((a^{(l-1)})^\top\delta^{(l)}dW)\Rightarrow\frac{L(y,\hat y)}{\partial W^{(l)}}=\delta^{(l)}(a^{(l-1)})^\top$   è‡ªåŠ¨æ¢¯åº¦è®¡ç®—  æ•°å€¼å¾®åˆ† ç¬¦å·å¾®åˆ† è‡ªåŠ¨å¾®åˆ†ï¼š$f:\mathbb{R}^N\rightarrow\mathbb{R}^M$  å‰å‘æ¨¡å¼ï¼š$N$ åå‘æ¨¡å¼ï¼š$M$     ä¼˜åŒ–  éå‡¸ä¼˜åŒ–é—®é¢˜ æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ æ¢¯åº¦å¼¥æ•£é—®é¢˜    </description>
    </item>
    
    <item>
      <title>3-CNN</title>
      <link>https://zhengzangw.com/notes/deep-learning/3-cnn/</link>
      <pubDate>Sun, 14 Jun 2020 00:00:00 +0000</pubDate>
      <author>zzw at smail.nju.edu.cn (Zangwei Zheng)</author>
      <guid>https://zhengzangw.com/notes/deep-learning/3-cnn/</guid>
      <description>å·ç§¯  å·ç§¯ï¼š$Y=W*X,y_{ij}=\sum_{u=1}^U\sum_{v=1}^V\omega_{uv}x_{i-u+1,j-v+1}$ äº’ç›¸å…³ï¼š$Y=W\otimes X=\text{rot180}(W)*X$  $Y\in\mathbb{R}^{M-U+1,N-V+1}$ æ·±åº¦å­¦ä¹ ä¸­å¸¸ç”¨äº’ç›¸å…³ä»£æ›¿å·ç§¯   å·ç§¯å±‚è¾“å‡ºé•¿åº¦ï¼ˆç¥ç»å…ƒæ•°é‡ï¼‰ï¼š$\frac{M-K+2P}{S}+1$  è¾“å…¥ç¥ç»å…ƒ $M$ æ­¥é•¿ $S$ å·ç§¯å¤§å° $K$ é›¶å¡«å……ï¼šè¾“å…¥å‘é‡ä¸¤ç«¯è¡¥ $P$ ä¸ªé›¶   å·ç§¯åˆ†ç±»  çª„å·ç§¯ï¼š$S=1,P=0$ å®½å·ç§¯ï¼š$S=1,P=K-1,W\tilde\otimes X=W\otimes\tilde{X}$ ç­‰å®½å·ç§¯ï¼š$S=1,P=\frac{(K-1)}{2}$   å·ç§¯æ•°å­¦æ€§è´¨ $Y=W\otimes X$  $\text{rot180}(W)\tilde{\otimes}X=\text{rot180}(X)\tilde{\otimes}W$ $\frac{\partial f(Y)}{\partial W}=\frac{\partial f(Y)}{\partial Y}\otimes X$ $\frac{f(Y)}{\partial X}=\text{rot180}(W)\tilde{\otimes}\frac{\partial f(Y)}{\partial Y}$   å…¶å®ƒå·ç§¯æ–¹å¼  è½¬ç½®å·ç§¯ï¼ˆåå·ç§¯ï¼‰ï¼šä»ä½ç»´åˆ°é«˜ç»´çš„æ˜ å°„ å¾®æ­¥å·ç§¯ï¼š$S&amp;lt;1$ æˆ–åœ¨æ¯ä¸¤ä¸ªå‘é‡å…ƒç´ é—´æ’å…¥ $D$ ä¸ª 0ï¼Œå¯å¾— $(D+1)\times(M-1)+K$ ç»´çš„å‘é‡ ç©ºæ´å·ç§¯ï¼ˆå·ç§¯è†¨èƒ€ï¼‰ï¼šå·ç§¯æ ¸é—´å¢åŠ ç©ºæ´ï¼Œå¢å¤§æ„Ÿå—é‡    CNN  FNN å¤„ç†å›¾åƒä¿¡æ¯  å‚æ•°è¿‡å¤š  $100\times100\times3$ åˆ™ç¬¬ä¸€éšè—å±‚æ¯ä¸ªç¥ç»å…ƒæœ‰ $30000$ å‚æ•° æƒé‡çŸ©é˜µæœ‰ $M_l\times M_{l-1}$ ä¸ªå‚æ•°   å±€éƒ¨ä¸å˜æ€§ç‰¹å¾   å·ç§¯å±‚ï¼š$z^{(l)}=\omega^{(l)}\otimes a^{(l-1)}+b^{(l)}$  å±€éƒ¨è¿æ¥ï¼šå·ç§¯å±‚ä¸­æ¯ä¸ªç¥ç»å…ƒåªå’Œå‰ä¸€å±‚ä¸­æŸä¸ªå±€éƒ¨çª—å£å†…çš„ç¥ç»å…ƒç›¸è¿æ„æˆå±€éƒ¨è¿æ¥ç½‘ç»œ æƒé‡å…±äº«ï¼š$\omega^{(l)}$ å¯¹æ‰€æœ‰ç¥ç»å…ƒç›¸åŒï¼Œä¸€ä¸ªå·ç§¯æ ¸åªæ•æ‰è¾“å…¥æ•°æ®ä¸­çš„ä¸€ç§ç‰¹å®šçš„å±€éƒ¨ç‰¹å¾ å…± $K+1$ ä¸ªå‚æ•°   å·ç§¯å±‚  è¾“å…¥ç‰¹å¾æ˜ å°„ç»„ï¼š$\mathcal{X}\in\mathbb{R}^{M\times N\times D}$ ä¸‰ç»´å¼ é‡ï¼Œåˆ‡ç‰‡ $X^d\in\mathbb{R}^{M\times N}$ ä¸ºä¸€ä¸ªè¾“å…¥ç‰¹å¾æ˜ å°„ è¾“å‡ºçŠ¶æ€æ˜ å°„ç»„ï¼š$\mathcal{Y}\in\mathbb{R}^{M&#39;\times N&#39;\times P}$ ä¸‰ç»´å¼ é‡ï¼Œåˆ‡ç‰‡ $Y^p\in\mathbb{R}^{M&#39;\times N&#39;}$ å·ç§¯æ ¸ï¼š$\mathcal{W}\in\mathbb{R}^{U\times V\times P\times D}$ï¼Œåˆ‡ç‰‡ $W^{p,d}\in\mathbb{R}^{U\times V}$ ä¸ºä¸€ä¸ªäºŒç»´å·ç§¯æ ¸ $Z^p=W^p\otimes X+b^p=\sum_{d=1}^DW^{p,d}\otimes X^d+b^p$ $Y^p=f(Z^p)$   æ±‡èšå±‚  æœ€å¤§æ±‡èšï¼š$y_{m,n}^d=\max_{i\in R_{m,n}^d}x_i$ å¹³å‡æ±‡èšï¼š$y_{m,n}^d=\frac{1}{|R_{m,n}^d|}\sum_{i\in R_{m,n}^d}x_i$   åå‘ä¼ æ’­ç®—æ³•  $\delta^{(l,p)}=\frac{\partial L}{\partial Z^{(l,p)}}$ æ±‡èšå±‚ï¼š$\delta^{(l,p)}=\frac{\partial L}{\partial Z^{(l,p)}}=f&#39;_l(Z^{(l,p)}\odot\text{up}(\delta^{(l+1,p)})$ èšé›†å±‚ï¼š$\delta^{(l,d)}=f&#39;l(Z^{(l,d)})\cdot\sum{P=1}^P(\text{rot180}(W^{(l+1,p,d)}\tilde\otimes\delta^{(l+1,p)}))$    Backbones  LeNet-5(1998)  è¿æ¥è¡¨ è¾“å‡ºå±‚ä¸º RBF å‡½æ•°   AlexNet(2012)  GPU è®­ç»ƒ å±€éƒ¨å“åº”å½’ä¸€   Inception  Inception æ¨¡å—ï¼šä¸åŒå·ç§¯æ ¸å¾—åˆ°ç»“æœå†æ·±åº¦ä¸Šå †å ä½œä¸ºè¾“å‡º Inception v1 (GoogLeNet, 2015) Inception v3 (2016)   ResNet  æ®‹å·®è¿æ¥ï¼š$h(x)=x+(h(x)-x)$ ResNet-50   VGG  </description>
    </item>
    
    <item>
      <title>4-RNN</title>
      <link>https://zhengzangw.com/notes/deep-learning/4-rnn/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:00 +0000</pubDate>
      <author>zzw at smail.nju.edu.cn (Zangwei Zheng)</author>
      <guid>https://zhengzangw.com/notes/deep-learning/4-rnn/</guid>
      <description>è®°å¿†èƒ½åŠ›   å»¶æ—¶ç¥ç»ç½‘ç»œï¼šéè¾“å‡ºå±‚å‰å¢åŠ å»¶æ—¶å™¨
 $h_t^{(l)}=f(h_t^{(l)},h_{t-1}^{(l-1)},\cdots,h^{(l-1)}_{t-K})$ åœ¨æ—¶é—´ç»´åº¦ä¸Šå…±äº«æƒå€¼    æœ‰å¤–éƒ¨è¾“å…¥çš„éçº¿æ€§ç½‘ç»œï¼šæ¯ä¸ªæ—¶åˆ» $t$ æœ‰ä¸€ä¸ªå¤–éƒ¨è¾“å…¥ï¼Œäº§ç”Ÿä¸€ä¸ªè¾“å‡º $y_t$
 è‡ªå›å½’æ¨¡å‹ï¼š$y_t=\omega_0+\sum_{k=1}^K\omega_ky_{t-k}+\epsilon_t$ æœ‰å¤–éƒ¨è¾“å…¥çš„éçº¿æ€§è‡ªå›å½’æ¨¡å‹ï¼š$y_t=f(x_t,x_{t-1},\cdots,x_{t-{K_x}},y_{t-1},y_{t-2},\cdots,y_{t-K_y})$    å¾ªç¯ç¥ç»ç½‘ç»œï¼š$h_t=f(h_{t-1},x_t)$
  å¾ªç¯ç¥ç»ç½‘ç»œçš„é€šç”¨è¿‘ä¼¼å®šç†ï¼ˆ2009ï¼‰ï¼šä»¥ä»»ä½•å‡†ç¡®ç‡è¿‘ä¼¼ä»»ä½•ä¸€ä¸ªéçº¿æ€§åŠ¨åŠ›ç³»ç»Ÿ
$$s_t=g(s_{t-1},x_t)\newline y_t=o(s_t)$$
  å›¾çµå®Œå¤‡ï¼ˆ1991ï¼‰ï¼šæ‰€æœ‰å›¾çµæœºå¯ä»¥è¢«ä¸€ä¸ªç”±ä½¿ç”¨ Sigmoid å‹æ¿€æ´»å‡½æ•°çš„ç¥ç»å…ƒæ„æˆçš„å…¨è¿æ¥å¾ªç¯ç½‘ç»œè¿›è¡Œæ¨¡æ‹Ÿ
    å¤–éƒ¨è®°å¿†å•å…ƒ
  RNN  ç®€å•ç¥ç»ç½‘ç»œ  $z_t=Uh_{t-1}+Wx_{t}+b$ $h_t=f(z_t)$ $y_t=Vh_t$   åº”ç”¨æ¨¡å¼  åºåˆ—åˆ°ç±»åˆ«  $x_{1:T}=(x_1,\cdots,x_T)$ æŒ‰ä¸åŒæ—¶åˆ»è¾“å…¥åˆ°ç½‘ç»œä¸­ $y\in{1,\cdots,C}$ åºåˆ—ç‰¹å¾ï¼š$h_T$ or $\frac{1}{T}\sum_{t=1}^Th_t$   åŒæ­¥åºåˆ—åˆ°åºåˆ—ï¼ˆåºåˆ—æ ‡æ³¨ï¼‰  $x_{1:T}=(x_1,\cdots,x_T)$ æŒ‰ä¸åŒæ—¶åˆ»è¾“å…¥åˆ°ç½‘ç»œä¸­ $y_{1:T}=(y_1,\cdots,y_T)$ $\hat y_t=g(h_t),\forall t\in[1,T]$   å¼‚æ­¥åºåˆ—åˆ°åºåˆ—ï¼ˆç¼–ç å™¨-è§£ç å™¨ï¼‰  $x_{1:T}=(x_1,\cdots,x_T)$ æŒ‰ä¸åŒæ—¶åˆ»è¾“å…¥åˆ°ç½‘ç»œï¼ˆç¼–ç å™¨ï¼‰ä¸­ $y_{1:M}=(y_1,\cdots,y_M)$ æŒ‰ä¸åŒæ—¶åˆ»è¾“å…¥åˆ°ç½‘ç»œï¼ˆè§£ç å™¨ï¼‰ä¸­ï¼Œåˆå§‹éšçŠ¶æ€ä¸º $h_T$ $\hat y_t=g(h_{T+t})$     éšæ—¶é—´åå‘ä¼ æ’­ï¼ˆBPTTï¼‰ï¼šæ¯å±‚å¯¹åº”æ¯ä¸ªæ—¶åˆ»  $\delta_{t,k}=\frac{\partial L_t}{\partial z_k}=\text{diag}(f&#39;(z_k))U^T\delta_{t,k+1}$ $\frac{\partial L_t}{\partial U}=\sum_{k=1}^t\delta_{t,k}h^T_{k-1}$ $\frac{\partial L}{\partial U}=\sum_{t=1}^T\sum_{k=1}^t\delta_{t,k}h^T_{k-1}$ åœ¨ä¸€æ¬¡å®Œæ•´å‰å‘ä¼ æ’­å’Œåå‘è®¡ç®—åæ‰èƒ½æ›´æ–°å‚æ•°   å®æ—¶å¾ªç¯å­¦ä¹ ï¼ˆRTRLï¼‰ å †å å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆSRNNï¼‰  å¾ªç¯å¤šå±‚æ„ŸçŸ¥æœºï¼ˆ1991ï¼‰ï¼š$h_t^{(l)}=f(U^{(l)}h_{t-1}^{(l)}+W^{(l)}h_t^{(l-1)}+b^{(l)})$   åŒå‘å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆBi-RNNï¼‰  é•¿ç¨‹ä¾èµ–é—®é¢˜  é•¿ç¨‹ä¾èµ–é—®é¢˜  æ¢¯åº¦æ¶ˆå¤±ï¼š$\frac{\partial L_t}{\partial h_k}$ æ¢¯åº¦æ¶ˆå¤±ï¼Œå‚æ•° $U$ æ›´æ–°ä¸»è¦é ç›¸é‚»çŠ¶æ€ $h_t=h_{t-1}+g(x_t,h_{t-1};\theta)$: æ¢¯åº¦çˆ†ç‚¸ï¼Œè®°å¿†å®¹é‡ä¸è¶³ æ¢¯åº¦çˆ†ç‚¸ï¼šä¸ç¨³å®š   é•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼ˆLSTM, 2000ï¼‰  å†…éƒ¨çŠ¶æ€ $c_t=f_t\odot c_{t-1}+i_t\odot \tilde{c}_t$ å¤–éƒ¨çŠ¶æ€ $h_t=o_t\odot \tanh(c_t)$ é—¨ ${0,1}$ é—å¿˜é—¨ $f_t=\sigma(W_fx_t+U_fh_{t-1}+b_f)$ æ§åˆ¶å†…éƒ¨çŠ¶æ€é—å¿˜å¤šå°‘ä¿¡æ¯ è¾“å…¥é—¨ $i_t=\sigma(W_ix_t+U_ih_{t-1}+b_i)$ æ§åˆ¶å€™é€‰çŠ¶æ€ä¿å­˜å¤šå°‘ä¿¡æ¯ è¾“å‡ºé—¨ $o_t=\sigma(W_0x_t+U_0h_{t-1}+b_0)$ æ§åˆ¶å†…éƒ¨çŠ¶æ€è¾“å‡ºå¤šå°‘ç»™å¤–éƒ¨çŠ¶æ€ å€™é€‰çŠ¶æ€ $\tilde{c}t=\tanh(Wx_t+Uh{t-1}+b)$   LSTM å˜ä½“  æ— é—å¿˜é—¨(1997) peephole è¿æ¥ï¼šä¸‰ä¸ªé—¨åŒæ—¶ä¾èµ–äºä¸Šä¸€æ—¶åˆ»è®°å¿†å•å…ƒ $c_{t-1}$ è€¦åˆè¾“å…¥é—¨ä¸é—å¿˜é—¨ï¼š$c_t=(1-i_t)\odot c_{t-1}+i_t\odot\tilde{c}_t$   é—¨æ§å¾ªç¯ç½‘ç»œï¼ˆGRU, 2014ï¼‰  $h_t=z_t\odot h_{t-1}+(1-z_t)\odot \tilde{h}_t$ æ›´æ–°é—¨ $z_t=\sigma(W_zx_t+U_zh_{t-1}+b_z)$ é‡ç½®é—¨ $r_t=\sigma(W_rx_t+U_rh_{t-1}+b_r)$ å€™é€‰çŠ¶æ€ $\tilde{h}t=\tanh(W_cx_t+U_h(r_t\odot h{t-1})+b)$    å›¾ç»“æ„  é€’å½’ç¥ç»ç½‘ç»œï¼ˆRecNNï¼‰ï¼š$h_i=f(h_{\pi_i})$  å»ºæ¨¡è‡ªç„¶è¯­è¨€å¥å­çš„è¯­ä¹‰   å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰  $m_t^{(v)}=\sum_{u\in N(v)}f(h^{(v)}_{t-1},h_{t-1}^{(u)},e^{(u,v)})$ $h_t^{(v)}=g(h_{t-1}^{(v)},m_t^{(v)})$ è¯»å‡ºå‡½æ•°ï¼š$o_t=g({h_T^{(v)}|v\in V})$    </description>
    </item>
    
    <item>
      <title>5-Optimization and Regularization</title>
      <link>https://zhengzangw.com/notes/deep-learning/5-optimization-and-regularization/</link>
      <pubDate>Tue, 16 Jun 2020 00:00:00 +0000</pubDate>
      <author>zzw at smail.nju.edu.cn (Zangwei Zheng)</author>
      <guid>https://zhengzangw.com/notes/deep-learning/5-optimization-and-regularization/</guid>
      <description>Optimization  é«˜ç»´å˜é‡éå‡¸ä¼˜åŒ–  éç‚¹ å¹³å¦æœ€å°å€¼ä¸å°–é”æœ€å°å€¼ å±€éƒ¨æœ€å°è§£ç­‰ä»·æ€§    ä¼˜åŒ–ç®—æ³•  å°æ‰¹é‡æ¢¯åº¦ä¸‹é™ï¼ˆæ‰¹é‡ï¼Œå­¦ä¹ ç‡ï¼Œæ¢¯åº¦ä¼°è®¡ï¼‰  $g_t=\frac{1}{K}\sum_{(x,y)\in S_t}\frac{\partial L(y,f(x;\theta))}{\partial\theta}$ $\theta\leftarrow\theta-\alpha g_t$   æ‰¹é‡å¤§å°é€‰æ‹©  çº¿æ€§æ”¾ç¼©è§„åˆ™ï¼šæ‰¹é‡å¤§å°å¢åŠ  $m$ å€æ—¶ï¼Œå­¦ä¹ ç‡ä¹Ÿå¢åŠ  $m$ å€ï¼ˆæ‰¹é‡å¤§å°è¾ƒå°æ—¶é€‚ç”¨ï¼‰ æ‰¹é‡è¶Šå¤§ï¼Œè¶Šæœ‰å¯èƒ½æ”¶æ•›åˆ°å°–é”æœ€å°å€¼;æ‰¹é‡è¶Šå°ï¼Œè¶Šæœ‰å¯èƒ½æ”¶æ•›åˆ° å¹³å¦æœ€å°å€¼   å­¦ä¹ ç‡è¡°å‡ï¼ˆé€€ç«ï¼‰  åˆ†æ®µå¸¸æ•°åˆ†è§£ï¼šæ¯ç»è¿‡ $T_1,\cdots,T_m$ æ¬¡è¿­ä»£ï¼Œè¡°å‡ä¸ºåŸæ¥çš„ $\beta_1,\cdots,\beta_m$ å€ é€†æ—¶è¡°å‡ï¼š$\alpha_t=\alpha_0\frac{1}{1+\beta\times t}$ æŒ‡æ•°è¡°å‡ï¼š$\alpha=\alpha_0\beta^t$ è‡ªç„¶æŒ‡æ•°è¡°å‡ï¼š$\alpha_0\exp(-\beta\times t)$ ä½™å¼¦è¡°å‡ï¼š$\alpha_t=\frac{1}{2}\alpha_0(1+\cos(\frac{t\pi}{T}))$   å­¦ä¹ ç‡é¢„çƒ­ï¼šæœ€åˆå‡ è½®ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡  é€æ¸é¢„çƒ­(2017)ï¼š$\alpha_t&#39;=\frac{t}{T&#39;}\alpha_0$   å‘¨æœŸæ€§å­¦ä¹ ç‡è°ƒæ•´  å¾ªç¯å­¦ä¹ ç‡ å¸¦çƒ­é‡å¯çš„éšæœºæ¢¯åº¦ä¸‹é™   AdaGrad(2011)ï¼šè‡ªé€‚åº”è°ƒæ•´å‚æ•°å­¦ä¹ ç‡  $\Delta\delta_t=-\frac{\alpha}{\sqrt{G_t+\epsilon}}\odot g_t$ æ¢¯åº¦å¹³æ–¹çš„ç´¯è®¡å€¼: $G_t=\sum_{\tau=1}^tg_\tau\odot g_\tau$ åå¯¼æ•°ç´¯ç§¯æ¯”è¾ƒå¤§ï¼Œå…¶å­¦ä¹ ç‡ç›¸å¯¹è¾ƒå°; ç›¸åï¼Œå¦‚æœå…¶åå¯¼æ•°ç´¯ç§¯è¾ƒå°ï¼Œå…¶å­¦ä¹ ç‡ç›¸å¯¹è¾ƒå¤§ã€‚ä½†æ•´ä½“æ˜¯éšç€è¿­ä»£æ¬¡æ•°çš„å¢åŠ ï¼Œå­¦ä¹ ç‡é€æ¸ç¼©å°   RMSProp(2012)ï¼šé¿å…å­¦ä¹ ç‡è¿‡æ—©è¡°å‡  $\Delta\theta_t=-\frac{\alpha}{\sqrt{G_t+\epsilon}}\odot g_t$ æ¢¯åº¦å¹³æ–¹çš„æŒ‡æ•°è¡°å‡ï¼š$G_t=\beta G_{t-1}+(1-\beta)g_t\odot g_t$   AdaDelta ç®—æ³•ï¼šå¼•å…¥å‚æ•°æ›´æ–°å·®å€¼ $\Delta\theta$ çš„å¹³æ–¹è°ƒæ•´å­¦ä¹ ç‡  $\Delta\theta_t=-\frac{\sqrt{\Delta X_{t-1}^2+\epsilon}}{\sqrt{G_t+\epsilon}}\odot g_t$ $\Delta X_{t-1}^2=\beta_1\Delta X_{t-2}^2+(1-\beta_1)\Delta\theta_{t-1}\odot\Delta\theta_{t-1}$   æ¢¯åº¦ä¼°è®¡ä¿®æ­£  åŠ¨é‡æ³•ï¼š$\Delta\theta_t=\rho\Delta_{t-1}-\alpha g_t$ Nesterov åŠ¨é‡æ³•ï¼š$\Delta\theta_t=\rho\Delta_{t-1}-\alpha g_t(\theta_{t-1}+\rho\Delta\theta_{t-1})$ Adam ç®—æ³•(2015)  $M_t=\beta_1 M_{t-1}+(1-\beta_1)g_t,\hat M_t=\frac{M_t}{1-\beta_1^t}$ $G_t=\beta_2G_{t-1}+(1-\beta_2)g_t\odot g_t,\hat G_t=\frac{G_t}{1-\beta_2^t}$ $\Delta\theta_t=-\frac{\alpha}{\hat G_t+\epsilon}\hat M_t$     æ¢¯åº¦æˆªæ–­  æŒ‰å€¼æˆªæ–­ï¼š$g_t=\max(\min(g_t,b),a)$ æŒ‰æ¨¡æˆªæ–­ï¼š$g_t=\frac{b}{|g_t|}g_t$    å‚æ•°åˆå§‹åŒ–  å›ºå®šæ–¹å·®å‚æ•°åˆå§‹åŒ–  é«˜æ–¯åˆ†å¸ƒåˆå§‹åŒ– å‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–   æ–¹å·®æ”¾ç¼©å‚æ•°åˆå§‹åŒ–  Xavier åˆå§‹åŒ–ï¼šæ–¹å·®ä¸º $\frac{2}{M_{l-1}+M_l}$  æ’ç­‰å‡½æ•° Logistic: 16 Tanh   He åˆå§‹åŒ–(Kaiming)ï¼šåå·®ä¸º $\frac{2}{M_{l-1}}$  ReLU     æ­£äº¤åˆå§‹åŒ–ï¼šèŒƒæ•°ä¿æŒæ€§ $|\delta^{(l-1)}|^2=|\delta^{(l)}|^2$  é«˜æ–¯åˆ†å¸ƒåˆå§‹åŒ–åï¼ŒSVD åˆ†è§£å¹¶å–ä¸€ä¸ªæ­£äº¤çŸ©é˜µä½œä¸ºæƒé‡    æ•°æ®é¢„å¤„ç†  å°ºåº¦ä¸å˜æ€§ï¼šç®—æ³•åœ¨ç¼©æ”¾éƒ¨åˆ†ç‰¹å¾åä¸å½±å“å­¦ä¹ å’Œé¢„æµ‹ å½’ä¸€åŒ– ç™½åŒ–ï¼šé™ä½å†—ä½™æ€§ æ•°æ®å¢å¼ºï¼šRotation, Flip, Zoom In/Out, Shift, Noise  ä¼˜åŒ–åœ°å½¢  ReLU æ¿€æ´»å‡½æ•° æ®‹å·®è¿æ¥ é€å±‚å½’ä¸€åŒ–  æ‰¹é‡å½’ä¸€åŒ–ï¼ˆBNï¼‰ï¼š$\text{BN}_{\gamma,\beta}(z^{(l)})=\frac{z^{(l)}-\mu_B}{\sqrt{\sigma_B^2+\epsilon}}\odot\gamma+\beta$  $\mu_B=\frac{1}{K}\sum_{k=1}^Kz^{(k,l)}$   å±‚å½’ä¸€åŒ–ï¼ˆLNï¼‰ï¼š$\text{LN}_{\gamma,\beta}(z_t^{(l)})=\frac{z^{(l)}-\mu}{\sqrt{\sigma^2+\epsilon}}\odot\gamma+\beta$  $\mu=\frac{1}{\mathbb{M_l}}\sum_{i=1}^{M_I}z_i^{(l)}$   æƒé‡å½’ä¸€åŒ–ï¼šé€šè¿‡å†å‚æ•°åŒ–å°†æƒé‡åˆ†ä¸ºé•¿åº¦ä¸æ–¹å‘  $W_{i,:}=\frac{g_i}{|v_i|}v_i$   å±€éƒ¨å“åº”å½’ä¸€åŒ–ï¼ˆLRNï¼‰    è¶…å‚æ•°ä¼˜åŒ–  è¶…å‚æ•°ï¼šç½‘ç»œç»“æ„ã€ä¼˜åŒ–å‚æ•°ã€æ­£åˆ™åŒ–å‚æ•° å›°éš¾  ç»„åˆä¼˜åŒ–é—®é¢˜ è¯„ä¼°ä¸€ç»„å‚æ•°é…ç½®çš„æ—¶é—´ä»£ä»·é«˜   ç½‘æ ¼æœç´¢ éšæœºæœç´¢ è´å¶æ–¯ä¼˜åŒ– åŠ¨æ€èµ„æºåˆ†é… ç¥ç»æ¶æ„æœç´¢  ç½‘ç»œæ­£åˆ™åŒ–  $l_1$ æ­£åˆ™åŒ– $l_2$ æ­£åˆ™åŒ– å¼¹æ€§ç½‘ç»œè¡°å‡ æƒé‡è¡°å‡ï¼š$\theta_1\leftarrow (1-\beta)\theta_{t-1}-\alpha g_t$  æ ‡å‡†éšæœºæ¢¯åº¦ä¸‹é™ä¸­ä¸ $l_2$ æ­£åˆ™åŒ–ç­‰ä»·   æå‰åœæ­¢ï¼šä½¿ç”¨éªŒè¯é›†é”™è¯¯ä»£æ›¿æœŸæœ›é”™è¯¯ ä¸¢å¼ƒæ³•  è®­ç»ƒæ—¶ï¼š$\text{mask}(x)=m\odot x, m$ ä»¥æ¦‚ç‡ä¸º $p$ çš„ä¼¯åŠªåˆ©åˆ†å¸ƒéšæœºç”Ÿæˆ æµ‹è¯•æ—¶ï¼š$\text{mask}(x)=px$ é›†æˆå­¦ä¹ è§’åº¦ï¼šä¸¢å¼ƒç›¸å½“äºé‡‡æ ·ä¸€ä¸ªå­ç½‘ç»œ è´å¶æ–¯å­¦ä¹ è§’åº¦   æ ‡ç­¾å¹³æ»‘ï¼šè½¯ç›®æ ‡æ ‡ç­¾ï¼Œç»™å…¶ä½™ $K-1$ ä¸ªç±»æ¦‚ç‡ $\frac{\epsilon}{K-1}$  </description>
    </item>
    
    <item>
      <title>8-Methodology</title>
      <link>https://zhengzangw.com/notes/deep-learning/8-methodology/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0000</pubDate>
      <author>zzw at smail.nju.edu.cn (Zangwei Zheng)</author>
      <guid>https://zhengzangw.com/notes/deep-learning/8-methodology/</guid>
      <description>åŠç›‘ç£å­¦ä¹   è‡ªè®­ç»ƒï¼ˆSelf-Training, Self-Teaching, Bootstrappingï¼‰ï¼šå…ˆç”¨æ ‡æ³¨æ•°æ®è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œå°†é¢„æµ‹ç½®ä¿¡åº¦è¾ƒé«˜çš„æ ·æœ¬çš„ä½æ ‡ç­¾åŠ å…¥è®­ç»ƒé›†é‡æ–°è®­ç»ƒ ååŒè®­ç»ƒï¼ˆCo-Trainingï¼‰ï¼šåŸºäºä¸åŒè§†è§’çš„åˆ†ç±»å™¨ä¿ƒè¿›è®­ç»ƒ  åœ¨è®­ç»ƒé›†ä¸Šæ ¹æ®ä¸åŒè§†è§’åˆ†åˆ«è®­ç»ƒä¸¤ä¸ªæ¨¡å‹ $f_1$ å’Œ $f_2$ åœ¨æ— æ ‡æ³¨è®­ç»ƒé›†ä¸Šé¢„æµ‹ï¼Œå„é€‰å–é¢„æµ‹ç½®ä¿¡åº¦æ¯”è¾ƒé«˜çš„æ ·æœ¬åŠ å…¥è®­ç»ƒé›†ï¼Œé‡æ–°è®­ç»ƒä¸¤ä¸ªä¸åŒè§†è§’çš„æ¨¡å‹    å¤šä»»åŠ¡å­¦ä¹   å¤šä»»åŠ¡å­¦ä¹ ï¼šå½’çº³è¿ç§»å­¦ä¹ çš„ä¸€ç§ï¼Œåˆ©ç”¨ç›¸å…³ä»»åŠ¡ä¸­çš„ä¿¡æ¯ä½œä¸ºå½’çº³åç½®æé«˜æ³›åŒ–èƒ½åŠ› å…±äº«æ¨¡å¼  ç¡¬å…±äº«æ¨¡å¼ï¼šè®©ä¸åŒä»»åŠ¡çš„ç¥ç»ç½‘ç»œå…±åŒä½¿ç”¨ä¸€äº›å…±äº«æ¨¡å—æå–é€šç”¨ç‰¹å¾ è½¯å…±äº«æ¨¡å¼ï¼šæ¯ä¸ªä»»åŠ¡ä»å…¶å®ƒä»»åŠ¡è·å¾—ä¸€äº›ä¿¡æ¯ï¼ˆå¦‚éšçŠ¶æ€ã€æ³¨æ„åŠ›æœºåˆ¶ï¼‰ å±‚æ¬¡å…±äº«æ¨¡å¼ï¼šä¸€èˆ¬ç¥ç»ç½‘ç»œä¸­ä¸åŒå±‚æŠ½å–çš„ç‰¹å¾ç±»å‹ä¸åŒï¼Œä½å±‚ä¸€èˆ¬æŠ½å–ä¸€äº›ä½çº§çš„å±€éƒ¨ç‰¹å¾ï¼Œé«˜å±‚æŠ½å–ä¸€äº›é«˜çº§çš„æŠ½è±¡è¯­ä¹‰ç‰¹å¾ å…±äº«-ç§æœ‰æ¨¡å¼ï¼šå°†å…±äº«æ¨¡å—å’Œä»»åŠ¡ç‰¹å®š(ç§æœ‰)æ¨¡å—çš„è´£ä»»åˆ†å¼€    è¿ç§»å­¦ä¹   é¢†åŸŸï¼šä¸€ä¸ªæ ·æœ¬ç©ºé—´æå…¶åˆ†å¸ƒ $\mathcal{D}=(\mathcal{X},\mathcal{Y},p(x,y))$ æœºå™¨å­¦ä¹ ä»»åŠ¡ï¼šå»ºæ¨¡ $\mathcal{D}$ ä¸Šçš„æ¡ä»¶æ¦‚ç‡ $p(y|x)$  Inductive Trasfer Learning Different Tasks: $p_S(y|x)\neq p_T(y|x), p_S(x)=p_T(x)$
 Multi-task Learning: Source Domain Labels are available  learn source and target   Self-taught Learning: Source Domain Labels are unavailable  feature based: learn good feature on source fine-tuning: pretrain model    Transductive Transfer Learning $p_S(x,y)\neq p_T(x,y)$ï¼Œå‡è®¾æºé¢†åŸŸæœ‰å¤§é‡æ ‡è®°æ•°æ®ï¼Œç›®æ ‡é¢†åŸŸæœ‰æ— æ ‡è®°æ•°æ®</description>
    </item>
    
    <item>
      <title>9-Deep-Relief-Network</title>
      <link>https://zhengzangw.com/notes/deep-learning/9-deep-reilef-network/</link>
      <pubDate>Mon, 22 Jun 2020 00:00:00 +0000</pubDate>
      <author>zzw at smail.nju.edu.cn (Zangwei Zheng)</author>
      <guid>https://zhengzangw.com/notes/deep-learning/9-deep-reilef-network/</guid>
      <description>ç»å°”å…¹æ›¼æœº  åŠ¨åŠ›ç³»ç»Ÿï¼šæè¿°ä¸€ä¸ªç©ºé—´ä¸­æ‰€æœ‰ç‚¹éšæ—¶é—´å˜åŒ–æƒ…å†µ Boltzmann Machine: a Stochastic Dynamical System  æ¯ä¸ªéšæœºå˜é‡äºŒå€¼ï¼š$X\in{0,1}^K$ï¼Œå¯è§‚å¯Ÿå˜é‡ $V$ï¼Œéšå˜é‡ $H$ æ‰€æœ‰ç»“ç‚¹å…¨è¿æ¥ æ¯ä¸¤ä¸ªå˜é‡é—´å½±å“å¯¹ç§°   ç»å°”å…¹æ›¼åˆ†å¸ƒï¼š$p(x)=\frac{1}{Z}\exp(\frac{-E(x)}{T})$  $E(x)=E(X=x)=-(\sum_{i&amp;lt;j}\omega_{ij}x_ix_j+\sum_ib_ix_i)$ $\frac{p_\alpha}{p_\beta}=\exp(\frac{E_\beta-E_\alpha}{kT})$   å…¨æ¡ä»¶æ¦‚ç‡ï¼š$p(x_i=1|x_{\backslash i})=\sigma(\frac{\sum_j\omega_{ij}x_j+b_i}{T})$ ç”Ÿæˆæ¨¡å‹ï¼šå‰å¸ƒæ–¯é‡‡æ ·ç”Ÿæˆæœä» $p(x)$ çš„å‡½æ•°  éšæœºé€‰æ‹©å˜é‡ $X_i$ï¼Œæ ¹æ® $p(x_i|x_{\backslash i})$ è®¾ç½®çŠ¶æ€ï¼Œè¿è¡Œåˆ°çƒ­å¹³è¡¡ $T$ è¶Šé«˜è¶Šå®¹æ˜“è¾¾åˆ°çƒ­å¹³è¡¡ $T\rightarrow+\infty$: æ¯ä¸ªçŠ¶æ€ä¸€æ · $T\rightarrow 0$ï¼šé€€åŒ–ä¸º Hopfield ç½‘ç»œ   æ¨¡æ‹Ÿé€€ç«å¯»æ‰¾å…¨å±€æœ€ä¼˜è§£ï¼šä»¥æ¦‚ç‡ $\sigma(\frac{\Delta E_i(x_{\backslash i})}{T})$ å°†å˜é‡è®¾ç½®ä¸º 1 å‚æ•°å­¦ä¹   å¯è§‚æµ‹å˜é‡ $v\in{0,1}^{K_v}$ éšå˜é‡ï¼š$h\in{0,1}^{K_h}$ å¯¹æ•°ä¼¼ç„¶ï¼š$L(D;W,b)=\frac{1}{N}\sum_{n=1}^N\log p(\hat v^{(n)};W,b)$    å—é™ç»å°”å…¹æ›¼æœº  éšå˜é‡ä¸å¯è§‚å¯Ÿå˜é‡å…¨è¿æ¥ $E(v,h)=-a^\top v-b^\top h-v^\top Wh$ $p(v,h)=\frac{1}{Z}\exp(-E(v,h))$ ç”Ÿæˆæ¨¡å‹  $p(v_i|v_{\backslash i,h})=p(v_i|h)$ $p(v_i=1|h)=\sigma(a_i+\sum_j\omega_{ij}h_j)$ å‰å¸ƒæ–¯é‡‡æ ·ï¼šå¹¶è¡Œå¯¹æ‰€æœ‰éšå˜é‡/å¯è§‚æµ‹å˜é‡é‡‡æ ·ï¼Œå¿«é€Ÿè¾¾åˆ°çƒ­å¹³è¡¡   å‚æ•°å­¦ä¹  å¯¹æ¯”æ•£åº¦ç®—æ³• å—é™ç»å°”å…¹æ›¼æœºç±»å‹  ä¼¯åŠªåˆ©-ä¼¯åŠªåˆ© BB-RBM é«˜æ–¯-ä¼¯åŠªåˆ© GB-RBM ä¼¯åŠªåˆ©-é«˜æ–¯ BG-RBM    æ·±åº¦ä¿¡å¿µç½‘ç»œ  æ¯å±‚å˜é‡ä¾èµ–äºä¸Šä¸€å±‚å˜é‡ï¼Œæœ€åº•å±‚ä¸ºå¯è§‚æµ‹å˜é‡ é€å±‚è®­ç»ƒï¼šæ¯å±‚çœ‹åšç»å°”å…¹æ›¼æœº  </description>
    </item>
    
    <item>
      <title>7-Unsupervised Learning</title>
      <link>https://zhengzangw.com/notes/deep-learning/7-unsupervised/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0000</pubDate>
      <author>zzw at smail.nju.edu.cn (Zangwei Zheng)</author>
      <guid>https://zhengzangw.com/notes/deep-learning/7-unsupervised/</guid>
      <description>Unsupervised Feature Learning   PCA
  Sparse Codingï¼ˆå­—å…¸å­¦ä¹ ï¼‰
  è‡ªç¼–ç å™¨
  ç¼–ç å™¨ï¼š$f:\mathbb{R}^D\rightarrow\mathbb{R}^M$
  è§£ç å™¨ï¼š$g:\mathbb{R}^M\rightarrow\mathbb{R}^D$
  ä¼˜åŒ–ç›®æ ‡ï¼šæœ€å°åŒ–é‡æ„é”™è¯¯
$$L=\sum_{n=1}^N|x^{(n)}-g(f(x^{(n)}))|+\lambda|W|^2$$
  æ†ç»‘æƒé‡ï¼š$W^{(2)}=W^{(1)\top}$
    ç¨€ç–è‡ªç¼–ç å™¨
  $M&amp;gt;D$ ä¸” $z$ ç¨€ç–
$$L=\sum_{n=1}^N|x^{(n)}-g(f(x^{(n)}))|+\eta\rho(Z)+\lambda|W|^2$$
  ç¨€ç–æ€§åº¦é‡å‡½æ•°ï¼š$\rho$
  $l_1$ èŒƒæ•°ï¼š$\rho(z)=\sum_{m=1}^M|z_m|$
  å¯¹æ•°å‡½æ•°ï¼š$\rho(z)=\sum_{m=1}^M\log(1+z_m^2)$
  æŒ‡æ•°å‡½æ•°ï¼š$\rho(z)=\sum_{m=1}^M-\exp(-z_m^2)$
  $\rho(z)=\sum_{j=1}^p\text{KL}(\rho^*|\hat\rho_j)$
ç¬¬ $j$ ä¸ªç¥ç»å…ƒæ¿€æ´»æ¦‚ç‡è¿‘ä¼¼ï¼ˆå¹³å‡æ´»æ€§å€¼ï¼‰ï¼š$\hat\rho_j=\frac{1}{N}\sum_{n=1}^Nz_j^{(n)}$
      å †å è‡ªç¼–ç å™¨
  é™å™ªè‡ªç¼–ç å™¨ï¼šå…ˆæ ¹æ®ä¸€ ä¸ªæ¯”ä¾‹ $ğœ‡$ éšæœºå°† $ğ’™$ çš„ä¸€äº›ç»´åº¦çš„å€¼è®¾ç½®ä¸º $0$ï¼Œå¾—åˆ°ä¸€ä¸ªè¢«æŸåçš„å‘é‡ $ğ’™Ìƒ$ï¼Œç„¶åå°†è¢«æŸåçš„å‘é‡ $ğ’™Ìƒ$ è¾“å…¥ç»™è‡ªç¼–ç å™¨å¾—åˆ°ç¼–ç  $ğ’›$ï¼Œå¹¶é‡æ„å‡ºæ— æŸçš„åŸå§‹è¾“å…¥ $ğ’™$ã€‚</description>
    </item>
    
    <item>
      <title>æ³¨æ„åŠ›æœºåˆ¶ä¸å¤–éƒ¨è®°å¿†</title>
      <link>https://zhengzangw.com/notes/deep-learning/6-attention-and-memory/</link>
      <pubDate>Tue, 16 Jun 2020 00:00:00 +0000</pubDate>
      <author>zzw at smail.nju.edu.cn (Zangwei Zheng)</author>
      <guid>https://zhengzangw.com/notes/deep-learning/6-attention-and-memory/</guid>
      <description>æ³¨æ„åŠ›æœºåˆ¶  è®¤çŸ¥ç¥ç»ç§‘å­¦ä¸­çš„æ³¨æ„åŠ›  èšç„¦å¼æ³¨æ„åŠ› åŸºäºæ˜¾è‘—æ€§çš„æ³¨æ„åŠ› é¸¡å°¾é…’ä¼šæ•ˆåº”   åŸºäºæ˜¾è‘—æ€§çš„æ³¨æ„åŠ›æœºåˆ¶ï¼šæœ€å¤§æ±‡èšã€é—¨æ§ æ³¨æ„åŠ›åˆ†å¸ƒï¼š  è¾“å…¥å˜é‡ï¼š$[x_1,\cdots,x_N]$ æŸ¥è¯¢å˜é‡ï¼š$q$ æ³¨æ„åŠ›å˜é‡ï¼š$z=n$ é€‰æ‹©ç¬¬ $n$ ä¸ªè¾“å…¥å˜é‡ æ³¨æ„åŠ›æ‰“åˆ†å‡½æ•°ï¼š$s(x,q)$  åŠ æ€§æ¨¡å‹ï¼š$s(x,q)=v^\top \tanh(Wx+Uq)$ ç‚¹ç§¯æ¨¡å‹ï¼š$s(x,q)=x^\top q$ ç¼©æ”¾ç‚¹ç§¯æ¨¡å‹ï¼š$s(x,q)=\frac{x^\top q}{\sqrt{D}}$ åŒçº¿æ€§æ¨¡å‹ï¼š$s(x,q)=x^\top Wq$   æ³¨æ„åŠ›åˆ†å¸ƒï¼š$\alpha_n=p(z=n|X,q)=\text{softmax}(s(x_n,q))$   è½¯æ€§æ³¨æ„åŠ›æœºåˆ¶ï¼š$\text{att}(X,q)=\sum_{n=1}^N\alpha_nx_n$ ç¡¬æ€§æ³¨æ„åŠ›æœºåˆ¶ï¼šæ— æ³•ä½¿ç”¨åå‘è½¬æ’­ï¼Œé€šå¸¸ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒ  $\text{att}=x_{\hat n},\hat n=\arg\max\alpha_n$ éšæœºé‡‡æ ·   é”®å€¼å¯¹æ³¨æ„åŠ›  è¾“å…¥ä¿¡æ¯ï¼š$[(k_1,v_1),\cdots,(k_N,v_N)]$ æ³¨æ„åŠ›å‡½æ•°ï¼š$\sum_{n=1}^N\frac{\exp(s(k_n,q))}{\sum_j\exp(s(k_j,q))}v_n$   å¤šå¤´æ³¨æ„åŠ›ï¼š$\text{att}((K,V),Q)=\oplus\text{att}((K,V),q_i)$ ç»“æ„åŒ–æ³¨æ„åŠ› æŒ‡é’ˆç½‘ç»œï¼ˆ2015ï¼‰ï¼šåºåˆ—åˆ°åºåˆ—æ¨¡å‹ï¼Œè¾“å‡ºä¸‹æ ‡  $p(c_{1:M}|x_{1:N})=\prod_{m=1}^M p(c_m|c_{1:(m-1)},x_{1:N})\approx\prod_{m=1}^Mp(c_m|x_{c1:c_{m-1}},x_{1:N})$ $p(c_m|c_{1:{(m-1)},x_{1:N}})=\text{softmax}(s_{m,n})$ $s_{m,n}=v^\top\tanh(Wx_n+Uh_m)$    è‡ªæ³¨æ„åŠ›æ¨¡å‹  å˜é•¿å‘é‡åºåˆ—  å·ç§¯ç½‘ç»œæˆ–å¾ªç¯ç½‘ç»œç¼–ç  è‡ªæ³¨æ„åŠ›æ¨¡å‹ï¼ˆå†…éƒ¨æ³¨æ„åŠ›æ¨¡å‹ï¼‰   å¦‚æœè¦å»ºç«‹è¾“å…¥åºåˆ—ä¹‹é—´çš„é•¿è·ç¦»ä¾èµ–å…³ç³»ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä¸¤ç§æ–¹æ³•ï¼šä¸€ç§æ–¹æ³•æ˜¯å¢åŠ ç½‘ç»œçš„å±‚æ•°ï¼Œé€šè¿‡ä¸€ä¸ªæ·±å±‚ç½‘ç»œæ¥è·å–è¿œè·ç¦»çš„ä¿¡æ¯äº¤äº’ï¼Œå¦ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨å…¨è¿æ¥ç½‘ç»œ QKV æ¨¡å¼  è¾“å…¥åºåˆ—ï¼š$X=[x_1,\cdots,x_N]\in\mathbb{R}^{D_x\times N}$ è¾“å‡ºåºåˆ—ï¼š$H=[h_1,\cdots,h_N]\in\mathbb{R}^{D_v\times N}$ æŸ¥è¯¢å‘é‡ï¼š$q_i\in\mathbb{R}^{D_k},Q=W_qX$ é”®å‘é‡ï¼š$k_i,Q=W_qX\in\mathbb{R}^{D_k\times N}$ å€¼å‘é‡ï¼š$v_i,V=W_vX\in\mathbb{R}^{D_v\times N}$ $h_n=\text{att}((K,V),q_n)$    è®°å¿†  äººè„‘è®°å¿†  æ•´ä½“æ•ˆåº”å‚¨å­˜ï¼ˆåˆ†å¸ƒå¼ï¼‰ å‘¨æœŸæ€§  é•¿æœŸè®°å¿†ï¼ˆç»“æ„è®°å¿†ï¼ŒçŸ¥è¯†ï¼‰ çŸ­æœŸè®°å¿† å·¥ä½œè®°å¿†ï¼ˆçº¦ 4 ç»„é¡¹ç›®ï¼‰   è”æƒ³è®°å¿†ï¼šåŸºäºè”æƒ³æ£€ç´¢    è®°å¿†å¢å¼ºç¥ç»ç½‘ç»œï¼ˆMANN/MNï¼‰  åŸºæœ¬æ¨¡å—  ä¸»ç½‘ç»œï¼ˆæ§åˆ¶å™¨ï¼‰ å¤–éƒ¨è®°å¿†å•å…ƒï¼šåˆ†ä¸ºå¤šä¸ªè®°å¿†ç‰‡æ®µ $M=[m_1,\cdots,m_N]$ è¯»å–æ¨¡å—ï¼šæ ¹æ®ä¸»ç½‘ç»œçš„æŸ¥è¯¢å‘é‡ $q_r$ï¼Œè¯»å– $r=R(M,q_r)$ å†™å…¥æ¨¡å—ï¼šæ ¹æ®ä¸»ç½‘ç»œçš„æŸ¥è¯¢å‘é‡ $q_\omega$ å’Œéœ€å†™å…¥ä¿¡æ¯ $a$ æ›´æ–° $M=W(M,q_\omega,a)$   æŒ‰å†…å®¹å¯»å€ï¼šæ³¨æ„åŠ›æœºåˆ¶  $r=\sum_{n=1}^N\alpha_n m_n$ $\alpha=\text{softmax}(s(m_n,q_r))$   ç«¯åˆ°ç«¯è®°å¿†ç½‘ç»œï¼ˆMemN2N,2015ï¼‰ï¼šå¤–éƒ¨è®°å¿†åªè¯»  $m_{1:N}={m_1,\cdots,m_N}$ è½¬æ¢æˆä¸¤ç»„è®°å¿†ç‰‡æ®µ $A,C$ åˆ†åˆ«ç”¨æ¥å¯»å€å’Œè¾“å‡º $r=\sum_{n=1}^N\text{softmax}(a_n^\top q)c_n$ $y=f(q+r)$ å¤šè·³æ“ä½œï¼š$q^{(k)}=r^{(k-1)}+q^{(k-1)}$   ç¥ç»å›¾çµæœºï¼ˆ2014ï¼‰  å¤–éƒ¨è®°å¿†ï¼š$M\in\mathbb{R}^{D\times N}$ æ§åˆ¶å™¨ï¼šç¥ç»ç½‘ç»œ æ¯ä¸ªæ—¶åˆ» $t$ï¼Œæ¥å— $x_t,h_{t-1},r_{t-1}$ è¾“å‡º $h_t$ï¼Œç”ŸæˆæŸ¥è¯¢å‘é‡ $q_t$ï¼Œåˆ é™¤å‘é‡ $e_t$ å’Œå¢åŠ å‘é‡ $a_t$ è¯»æ“ä½œï¼š$\alpha_{t,n}=\text{softmax}(s(m_{t,n},q_t))$  è¯»å‘é‡ï¼š$r_t=\sum_{n=1}^N\alpha_{t,n}m_{t,n}$   å†™æ“ä½œï¼š$m_{t+1,n}=m_{t,n}(1-\alpha_{t,n}e_t)+\alpha_{t,n}\alpha_t$    åŸºäºç¥ç»åŠ¨åŠ›å­¦çš„è”æƒ³è®°å¿†  Hopfield ç½‘ç»œ  çŠ¶æ€ï¼š${+1,-1}$ æ›´æ–°è§„åˆ™ï¼š$s_i=s_i+\text{sgn}(\sum_{j=1}^M\omega_{ij}s_j+b_i)$ èƒ½é‡å‡½æ•°ï¼š$E=-\frac{1}{2}\sum_{i,j}\omega_{ij}s_is_j-\sum_ib_is_i$ æƒé‡å¯¹ç§°ï¼š$\omega_{ii}=0,\omega_{ij}=\omega_{ji}$ ç¨³å®šæ€§ï¼šèƒ½é‡å‡½æ•°å¤šæ¬¡è¿­ä»£åæ”¶æ•› å¸å¼•ç‚¹ï¼šç¨³å®šçŠ¶æ€ï¼Œå±€éƒ¨æœ€ä¼˜ç‚¹ï¼Œæœ‰é™ï¼Œç½‘ç»œå‚¨å­˜çš„æ¨¡å¼ ä¿¡æ¯å‚¨å­˜ï¼ˆå­¦ä¹ è§„åˆ™ï¼‰ï¼šèµ«å¸ƒè§„åˆ™ $\omega_{ij}=\frac{1}{N}\sum_{n=1}^Nx_i^{(n)}x_j^{(n)}$ å‚¨å­˜å®¹é‡ï¼šæ•°é‡ä¸º $M$ çš„äºŒå€¼ç¥ç»å…ƒç½‘ç»œï¼Œæ€»çŠ¶æ€æ•°ä¸º $2^M$ï¼Œæœ‰æ•ˆç¨³å®šç‚¹çŠ¶æ€æ•°å³å‚¨å­˜å®¹é‡  Hopfield: 0.</description>
    </item>
    
    <item>
      <title>Deep Learning</title>
      <link>https://zhengzangw.com/notes/deep-learning/deep-learning/</link>
      <pubDate>Sun, 02 Sep 2018 00:00:00 +0000</pubDate>
      <author>zzw at smail.nju.edu.cn (Zangwei Zheng)</author>
      <guid>https://zhengzangw.com/notes/deep-learning/deep-learning/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Deep Learning&lt;/em&gt;
&lt;a href=&#34;https://www.bilibili.com/video/av9770302/?p=5&#34;&gt;æå®æ¯…è¯¾ç¨‹&lt;/a&gt;
&lt;a href=&#34;http://speech.ee.ntu.edu.tw/~tlkagk/courses_MLDS17.html&#34;&gt;æå®æ¯…çš„ä¸»é¡µ&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;ç¬¬å…­ç« &#34;&gt;ç¬¬å…­ç« &lt;/h2&gt;
&lt;p&gt;Input -&amp;gt; FL -&amp;gt; FL -&amp;gt; FL -&amp;gt; Softmax -&amp;gt;&lt;/p&gt;
&lt;h3 id=&#34;è¾“å‡ºå•å…ƒ&#34;&gt;è¾“å‡ºå•å…ƒ&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;é«˜æ–¯è¾“å‡ºåˆ†å¸ƒçº¿æ€§å•å…ƒ&lt;/li&gt;
&lt;li&gt;Bernoulliè¾“å‡ºåˆ†å¸ƒsigmoidå•å…ƒ&lt;/li&gt;
&lt;li&gt;Multinoulliè¾“å‡ºåˆ†å¸ƒsoftmaxå•å…ƒ&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://zhengzangw.com/notes/deep-learning/11-deep-generative-network/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <author>zzw at smail.nju.edu.cn (Zangwei Zheng)</author>
      <guid>https://zhengzangw.com/notes/deep-learning/11-deep-generative-network/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://zhengzangw.com/notes/deep-learning/12-deep-reinforce-network/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <author>zzw at smail.nju.edu.cn (Zangwei Zheng)</author>
      <guid>https://zhengzangw.com/notes/deep-learning/12-deep-reinforce-network/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://zhengzangw.com/notes/deep-learning/13-sequence-generative/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <author>zzw at smail.nju.edu.cn (Zangwei Zheng)</author>
      <guid>https://zhengzangw.com/notes/deep-learning/13-sequence-generative/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
