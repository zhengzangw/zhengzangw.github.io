<!DOCTYPE html>
<html lang="en-us">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Introduction to Domain Adapation | Zangwei</title>

    
    <link rel="stylesheet" href="/scss/main.min.db87d7b55e29b75699acf73451f98e37f7029321133dd8ae45930563c6c76609.css" integity="sha256-24fXtV4pt1aZrPc0UfmON/cCkyETPdiuRZMFY8bHZgk=">

    <script type="text/javascript" src="/js/dark.js"></script>
<script>
  MathJax = {
    tex: {
      inlineMath: [["$", "$"]],
    },
    displayMath: [
      ["$$", "$$"],
      ["\[\[", "\]\]"],
    ],
    svg: {
      fontCache: "global",
    },
  };

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
></script>
</head><body class="app auto flex-container">
    <div class="flex-container flex-column"><nav>
    <hr>
    <div class="flex-container flex-row flex-row-full">
        
        <div class="nav-item">
            <a href="/about">[ About ]</a>
        </div>
        
        <div class="nav-item">
            <a href="/pdfs/resume.pdf">[ CV ]</a>
        </div>
        
        <div class="nav-item">
            <a href="/teach">[ Teaching ]</a>
        </div>
        
        <div class="nav-item">
            <a href="/posts">[ Posts ]</a>
        </div>
        
        <div class="nav-item">
            <a href="/notes">[ Notes ]</a>
        </div>
        
        <div class="nav-item">
            <a href="/friends">[ Friends ]</a>
        </div>
        
        <div class="nav-item btn btn-switch">
            <a>[ <span class="theme-name">Auto</span> ]</a>
        </div>
    </div>
    <hr>
</nav>
<div class="flex-passage flex-row flex-row-full">
            <div class="flex-column-20">
                <div class="return">
                    <a href=".."> RETURN </a>
                </div>
                <nav id="TableOfContents">
  <ul>
    <li><a href="#cnn-backbones">CNN backbones</a></li>
    <li><a href="#semantic-segmentation">Semantic Segmentation</a></li>
    <li><a href="#adversial">Adversial</a></li>
    <li><a href="#graphical-models">Graphical models</a></li>
    <li><a href="#transfer-learning">Transfer Learning</a>
      <ul>
        <li><a href="#inductive-trasfer-learning">Inductive Trasfer Learning</a></li>
        <li><a href="#transductive-transfer-learning">Transductive Transfer Learning</a></li>
        <li><a href="#unsupervised-transfer-learning">Unsupervised Transfer Learning</a></li>
      </ul>
    </li>
    <li><a href="#da-dataset">DA Dataset</a></li>
    <li><a href="#leading-results-in-da">Leading results in DA</a>
      <ul>
        <li><a href="#possible-points">Possible Points</a></li>
      </ul>
    </li>
  </ul>
</nav>
            </div>
            <main class="flex-column-80"><h2 id="cnn-backbones">CNN backbones</h2>
<p><a href="https://my.oschina.net/u/876354/blog/1637819">结构介绍</a></p>
<ul>
<li>LeNet5(1998)</li>
<li>AlexNet8(2012)</li>
<li>VGG(2014)
<ul>
<li>VGG16</li>
<li>VGG19</li>
</ul>
</li>
<li>GoogLeNet22(2014)
<ul>
<li>Inception v1-v4</li>
</ul>
</li>
<li>ResNet(2015)
<ul>
<li>ResNet50</li>
<li>ResNet101</li>
</ul>
</li>
<li>DRN-26</li>
</ul>
<h2 id="semantic-segmentation">Semantic Segmentation</h2>
<ul>
<li>$p_{ij}$: 被预测为 $j$ 类样本的 $i$ 类样本</li>
<li>Pixel Accuarcy: $\text{PA}=\frac{\sum_{i=0}^kp_{ii}}{\sum_{i=0}^k\sum_{j=0}^kp_{ij}}$</li>
<li>Mean Pixel Accuracy: $\text{MPA}=\frac{1}{k}\sum_{i=0}^k\frac{p_{ii}}{\sum_{j=0}^kp_{ij}}$</li>
<li>Mean Intersection over Union: $\text{MIoU}=\frac{1}{k}\sum_{i=0}^k\frac{p_{ii}}{\sum_{j=0}^kp_{ij}+\sum_{j=0}^kp_{ji}-p_{ii}}$</li>
<li>Frequency Weighted Intersection over Union: $\text{FWIoU}=\frac{1}{\sum_{i=0}^k\sum_{j=0}^kp_{ij}}\sum_{i=0}\frac{p_{ii}\sum_{j=0}^kp_{ij}}{\sum_{j=0}^kp_{ij}+\sum_{j=0}^kp_{ji}-p_{ii}}$</li>
</ul>
<p>架构</p>
<ul>
<li>FCN-8s</li>
<li>DeepLab V2</li>
</ul>
<h2 id="adversial">Adversial</h2>
<ul>
<li>GAN: $\min_G\max_D V(D,G)=E_{x\sim p_{\text{data}(x)}}[\log D(x)]+E_{z\sim p_z(z)}[\log (1-D(x))]$</li>
<li>cGAN: $\min_G\max_D V(D,G)=E_{x\sim p_{\text{data}(x|y)}}[\log D(x)]+E_{z\sim p_z(z)}[\log (1-D(x|y))]$
<ul>
<li>paired data generate</li>
</ul>
</li>
<li>BicycleGAN: diverse output</li>
<li>Cycle GAN: no need of paired data</li>
<li>泛化性：所有模型都是需要先用有限的训练样本来训练的，那么由这些有限样本训练得到的模型可不可以从这些有限训练样本中生成出新的样本，而非简单地记着训练集</li>
<li>GAN 的问题
<ul>
<li>训练过程难以收敛，经常出现震荡；实验结果随机，难以复现；</li>
<li>mode collapse：只生成某一模式</li>
<li>生成了一些没有意义、或者现实中不可能出现的图片</li>
</ul>
</li>
</ul>
<h2 id="graphical-models">Graphical models</h2>
<p><img src="https://pic2.zhimg.com/80/v2-714c1843f78b6aecdb0c57cdd08e1c6a_720w.jpg" alt="Graphical models"></p>
<h2 id="transfer-learning">Transfer Learning</h2>
<p>$D_S={X_S,f_S},T_S$
$D_T={X_T,f_T},T_T$</p>
<h3 id="inductive-trasfer-learning">Inductive Trasfer Learning</h3>
<p>Target Labels are all available</p>
<ul>
<li>Multi-task Learning: Source Domain Labels are available
<ul>
<li>同时学好 Source 和 Task</li>
</ul>
</li>
<li>Self-taught Learning: Source Domain Labels are unavailable
<ul>
<li>pre-trained model: 通过大型数据集学到的网络特征用于一个图片分类</li>
<li>Catastrophic Forgetting: 神经网络之前学习到的特征将灾难性遗忘
<ul>
<li>Progressive Neural Networks: 通过 Lateral Connection 的方式将一学习好的模型参数通过另一层网络教给一个新的任务，效率较低</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="transductive-transfer-learning">Transductive Transfer Learning</h3>
<p>Target Labels are unavailable</p>
<ul>
<li>Domain Adaptation：学习 domain-invariant feature 使得学习到的特征不受限于 Source Domain 而导致 over-fitting，缩小 co-variant shift</li>
</ul>
<h3 id="unsupervised-transfer-learning">Unsupervised Transfer Learning</h3>
<p>Source Labels are unavailable</p>
<h2 id="da-dataset">DA Dataset</h2>
<ul>
<li>Digital Recognition
<ul>
<li>MNIST</li>
<li>USPS</li>
<li>SVHM</li>
</ul>
</li>
<li>Autodriving
<ul>
<li>SYNTHIA: 1280x760</li>
<li>GTA5: 1914x1052</li>
<li>CityScapes</li>
<li>BDD100K</li>
<li>Mapillary</li>
</ul>
</li>
</ul>
<h2 id="leading-results-in-da">Leading results in DA</h2>
<p>GTA5-&gt;CitySpaces, VGG16-FCN8s, mIoU</p>
<ul>
<li>CyDADA: 35.4%
<ul>
<li>Cycle loss</li>
<li>Semantic consistency loss</li>
<li>Feature-level loss</li>
</ul>
</li>
<li>BDL: 41.3%
<ul>
<li>self-training</li>
</ul>
</li>
<li>PyCDA: 37.2%
<ul>
<li>Non adaptation</li>
<li>self-training: pixel level</li>
<li>curriculum domain adaptation: high level self-training</li>
</ul>
</li>
<li>DRPC: 36.1%
<ul>
<li>Domain Randomization: intepolation to cover all domain adaptation</li>
<li>images/domain pyramid consistency: high level semantic consistency</li>
</ul>
</li>
<li>MADAN(GTA5+SYNTHIA): 41.4%
<ul>
<li>directly make different adapt domains indistinguishable</li>
</ul>
</li>
<li>IMLE: diverse image generation
<ul>
<li>IMLE method</li>
</ul>
</li>
<li>Oracle: 60.3%</li>
</ul>
<h3 id="possible-points">Possible Points</h3>
<ul>
<li>self-training in DR</li>
<li>IMLE</li>
<li>better DR</li>
</ul>
</main>
        </div>

    </div>
</body></html>