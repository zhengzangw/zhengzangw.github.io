<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ml on Zangwei</title>
    <link>https://zhengzangw.com/tags/ml/</link>
    <description>Recent content in ml on Zangwei</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>zzw at smail.nju.edu.cn (Zangwei Zheng)</managingEditor>
    <webMaster>zzw at smail.nju.edu.cn (Zangwei Zheng)</webMaster>
    <lastBuildDate>Thu, 07 Nov 2019 00:00:00 +0000</lastBuildDate><atom:link href="https://zhengzangw.com/tags/ml/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>1-概论</title>
      <link>https://zhengzangw.com/notes/artificial-intelligence/1-introduction/</link>
      <pubDate>Tue, 10 Sep 2019 00:00:00 +0000</pubDate>
      <author>zzw at smail.nju.edu.cn (Zangwei Zheng)</author>
      <guid>https://zhengzangw.com/notes/artificial-intelligence/1-introduction/</guid>
      <description>科学与技术关系的探讨  周光绍  科学：正确反映客观世界现象、物质内部结构和运动规律的系统理论知识 技术：在科学指导下，总结实践经验，各方面的系统知识   白春礼  科学：发现、探索研究事物运动的客观规律 技术：[做什么、怎么做   人工智能  强人工智能：人工智能使探索人脑与意识的科学 弱人工智能：模拟人脑相应功能且得到应用，偏向于技术    何为人工智能  像人一样行动  图灵测试  自然语言处理 知识表示 自动推理 机器学习   完全图灵测试  计算机视觉 机器人学     像人一样思考  领会人脑用途  内省：捕捉思维过程 心理实验 脑成像   认知科学   合理地思考 合理地行动  学科交叉  哲学  图灵测试(1950)  西尔勒中文屋子(1980)：能否从表现来评判智能 人为陷阱：能否真的了解人类的智能水平 缸中之脑(1981) 反向图灵测试(CAPTCHA,2002)   智能的哲学发展  笛卡尔(1596-1650)：可通过可编程机械实现智能 莱布尼茨(1646-1716)：不存在预先设置的机器智能  磨坊论证：知觉的存在是对智能的存在不可或缺的吗？   霍布斯(1588-1679，符号流派哲学先驱)：机械化的心灵观，仅仅限制在理性（推理） 休谟(1711-1776，联结流派哲学先驱)：心智模型是“自底而上”构建的，最底层是感觉，其次是抽象和记忆，再上是想象 康德(1724-1804)：心智模型是知觉的“从上(知性)至下(高阶 知觉)” 和“自下(感性)而上(低阶知觉)”,两者不可或缺 霍布斯·德瑞福斯(1929-)：真实的思维是不可以被程序穷尽，依赖计算力的“智能”不是人类智能 罗德尼·布洛克斯（行为流派先驱）：世界是最大的认知模型，更重要的是如何由嵌入式的方式认知外部世界，而并不需要创造中间符号 乔姆斯基  大脑是“认知”的 大部分智力活动是“先天”的 模式是大脑认知的关键结构       数学 经济学  囚徒困境 投票悖论 冷扑大师：博弈均衡策略求解算法   神经科学 心理学 计算机工程 控制论 自动化 语言学  Spaif-Whorf 假说：语言决定人们对世界的理解   大数据  4V:Volume,Velocity,Variety,Veracity  多源异构数据 海量分布数据 流数据 交互型数据 图数据   4I:Inexact,Incremental,Integrated,Inductive 大数据的表示模型：数据表示如何充分体现大数据的内在规律 大数据的计算模型：超越样本多项式时间复杂度的大数据计算模型  在线学习 近似学习   大数据的决策模型：面向多个行为实体的大数据复杂决策技术（数据分析到博弈推理）    历史发展  孕育期(1943-1955) 达特茅斯会议(1956)  克劳德·香农 约翰·麦卡锡  搜索与剪枝   马文·明斯基  知识表示和推理   奥利弗·赛弗里奇 赫伯特·西蒙 &amp;amp; 阿兰·纽维尔   推理期(1952-1969)  第一次低潮  早期程序对其主题一无所知 求解问题的难解性；组合爆炸 流派之争 Perceptrons  符号学派（逻辑） 连接学派（仿生） 行为学派（控制）       知识期(1970-1980 末)  第二次高潮（符号学派成功） 专家系统 第二次低潮（五代机计划失败）   学习期  第三次高潮（机器学习的成功）   深度期 新一代人工智能五个方向  大数据智能 群体智能 跨媒体智能 混合增强智能 自主无人系统    智能 Agent  理性  依赖于：性能度量，先验知识，可能的行动，感知序列 对环境的先验知识  可以完成的行动：执行器 截止此时的感知序列：信息收集，传感器   期望性能最大化 完美：实际性能最大化   任务环境 = (Performance Measurement,Environment,Actuators,Sensors) PEAS 任务环境的性质  Observable: 传感器是否能在每个时间点上获得完整信息 Multi Agents: 存在其它 Agents Deterministic: 下一状态是否完全决定于当前转态与行为 Episodic Static or Dynamic  Dynamic: Agent 计算时环境会变化 Semi: 环境不变，但性能评价变化   离散/连续 环境已知/未知   Agent 函数：将感知信息映射到行动 Agent 程序：实现 Agent 函数 Agent = 体系结构（执行器，传感器，计算装置） + Agent 程序 Agent 程序  Table Driven Agent Simple Reflex Agent  RULE-MATCH 仅使用当前状态   Model Based Reflex Agent  拥有内部状态（模型） 使用当前状态与内部状态   Agent with Goal  不使用 RULE-MATCH 确定当前状态与内部状态及动作后果，与目标比较后选择执行   Agent with Utility   学习 Agent 表达能力  原子表示：单点 要素化表示：集合 结构化表示：逻辑等    解决问题  CV  人脸识别 姿态识别   NLP  自然语言生成 语音识别 虚拟助理   IR  推荐系统 搜索引擎   交叉  机器人 决策管理 自动驾驶 生物：基因组 医疗：辅助决策、医学信息分析 金融：量化交易、安全、服务 网络安全 教育    </description>
    </item>
    
    <item>
      <title>Introduction to Collaborative Filtering</title>
      <link>https://zhengzangw.com/posts/collaborative-filtering/</link>
      <pubDate>Thu, 07 Nov 2019 00:00:00 +0000</pubDate>
      <author>zzw at smail.nju.edu.cn (Zangwei Zheng)</author>
      <guid>https://zhengzangw.com/posts/collaborative-filtering/</guid>
      <description>&lt;h2 id=&#34;recommandation&#34;&gt;Recommandation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Demographic-based Recommendation&lt;/li&gt;
&lt;li&gt;Content-based Recommendation&lt;/li&gt;
&lt;li&gt;Collaborative Filtering-based Recommendation&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;collaborative-filtering&#34;&gt;Collaborative Filtering&lt;/h2&gt;
&lt;p&gt;Filtering: method of making automatic predictions about the interests of a user&lt;br&gt;
Collaborating: by collecting preferences or taste information from many users&lt;br&gt;
Underlying Assumption: if a person A has the same opinion as a person B on an issue, A is more likely to have B&amp;rsquo;s opinion on a different issue than that of a randomly chosen person.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Introduction to Meta Learning</title>
      <link>https://zhengzangw.com/posts/meta-learning/</link>
      <pubDate>Mon, 07 Oct 2019 00:00:00 +0000</pubDate>
      <author>zzw at smail.nju.edu.cn (Zangwei Zheng)</author>
      <guid>https://zhengzangw.com/posts/meta-learning/</guid>
      <description>&lt;h1 id=&#34;problem-statement&#34;&gt;Problem Statement&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Mechanistic view
&lt;ul&gt;
&lt;li&gt;DNN model that can read in an entire dataset and make predictions for new data point&lt;/li&gt;
&lt;li&gt;Training this network uses a meta-dataset, which itself consists of many datasets, each for a different task&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Probabilistic view
&lt;ul&gt;
&lt;li&gt;Extract prior information from a set of tasks taht allows effcient learning of new tasks&lt;/li&gt;
&lt;li&gt;Learning a new task this prior and training set to infer most likely posterior parameters&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;supervised learnings
&lt;ul&gt;
&lt;li&gt;$\arg\max\limits_{\phi}p(\phi|\mathcal{D})=\arg\max\limits_{\phi} \log p(\mathcal{D}|\phi)+\log p(\phi)$&lt;/li&gt;
&lt;li&gt;require large amounts of labeled data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Learning to Match</title>
      <link>https://zhengzangw.com/posts/learning-to-match/</link>
      <pubDate>Tue, 24 Sep 2019 00:00:00 +0000</pubDate>
      <author>zzw at smail.nju.edu.cn (Zangwei Zheng)</author>
      <guid>https://zhengzangw.com/posts/learning-to-match/</guid>
      <description>&lt;h1 id=&#34;problem&#34;&gt;Problem&lt;/h1&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;QA (Question Ansering)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Machine Comprehension&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dialogue Systems&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Ad-hoc Retrieval&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Learning to Rank&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;</description>
    </item>
    
    <item>
      <title>Lamda-2 Seminar</title>
      <link>https://zhengzangw.com/posts/seminar-19/</link>
      <pubDate>Wed, 11 Sep 2019 00:00:00 +0000</pubDate>
      <author>zzw at smail.nju.edu.cn (Zangwei Zheng)</author>
      <guid>https://zhengzangw.com/posts/seminar-19/</guid>
      <description>&lt;h1 id=&#34;summary&#34;&gt;Summary&lt;/h1&gt;
&lt;h2 id=&#34;审稿过程&#34;&gt;审稿过程&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Initial Check: 1~14 days
&lt;ul&gt;
&lt;li&gt;Editor Assistant 检查文章格式&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;With Editor：14~30 days
&lt;ul&gt;
&lt;li&gt;Associate Editor: 对文章进行初步审查&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Under Review(Peer Review)：7~180 days
&lt;ul&gt;
&lt;li&gt;PC 3-5: Give Scores and Review/Comments&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Required Review Completed：1~5 days
&lt;ul&gt;
&lt;li&gt;Senior PC(SPC): judge reviews&lt;/li&gt;
&lt;li&gt;Rebuttal&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Editor Decision
&lt;ul&gt;
&lt;li&gt;Area Chairs(AC): decide&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;数学
&lt;ul&gt;
&lt;li&gt;数字信号处理&lt;/li&gt;
&lt;li&gt;随机过程&lt;/li&gt;
&lt;li&gt;矩阵论&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>History</title>
      <link>https://zhengzangw.com/notes/machine-learning/others/</link>
      <pubDate>Sun, 14 Apr 2019 00:00:00 +0000</pubDate>
      <author>zzw at smail.nju.edu.cn (Zangwei Zheng)</author>
      <guid>https://zhengzangw.com/notes/machine-learning/others/</guid>
      <description>技术浪潮     神经网络 支持向量机 神经网络     年份 89-94 95-05 06-   代表性技术 BP 算法 核方法，统计学习理论 深度学习    生成式与判别式     判别式(discriminative) 生成式(generative)      对 $P(c\vert x)$ 建模 对 $P(c \vert x)=\frac{P(x,c)}{P(x)}$ 建模   实例 决策树，BP 神经网络，SVM 贝叶斯分类器   实际环境中问题 i.i.d. 改变，concept driven，后验概率不变     没有做“多余”工作 做了“多余”工作    神经网络发展史  第一阶段  1943 年, McCulloch 和 Pitts 提出第一个神经元数学模型, 即 M-P 模型, 并从原理上证明了人工神经网络能够计算任何算数和逻辑函数 1949 年, Hebb 发表《The Organization of Behavior》一书, 提出生物神经元学习的机理, 即 Hebb 学习规则 1958 年, Rosenblatt 提出感知机网络(Perceptron)模型和其学习规则 1960 年, Widrow 和 Hoff 提出自适应线性神经元(Adaline)模型和最小均方学习算法 1969 年, Minsky 和 Papert 发表《Perceptrons》一书, 指出单层神经网路不能解决非线性问题, 多层网络的训练算法尚无希望.</description>
    </item>
    
    <item>
      <title>Summary of Google 1st ML Camp (Shanghai)</title>
      <link>https://zhengzangw.com/posts/google-mlcamp-2019/</link>
      <pubDate>Sun, 20 Jan 2019 00:00:00 +0000</pubDate>
      <author>zzw at smail.nju.edu.cn (Zangwei Zheng)</author>
      <guid>https://zhengzangw.com/posts/google-mlcamp-2019/</guid>
      <description>&lt;h1 id=&#34;项目&#34;&gt;项目&lt;/h1&gt;
&lt;p&gt;三天内和两个队友合作完成了一个项目，基本是零基础，最后还能有展示的Demo，感觉很棒。总结这次项目(NLP)的开发流程如下&lt;/p&gt;
&lt;h2 id=&#34;开发流程&#34;&gt;开发流程&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;选题+创意构想（头脑风暴）&lt;/li&gt;
&lt;li&gt;数据集分析+数据可视化&lt;/li&gt;
&lt;li&gt;数据清理&lt;/li&gt;
&lt;li&gt;模型构建（先有个baseline，后面可以大家一起构想；baseline应该先满足end2end）&lt;/li&gt;
&lt;li&gt;Tuning （这个可以一直进行，但是要保证其它部分有充足时间）&lt;/li&gt;
&lt;li&gt;Demo （手机App&amp;gt;=网页&amp;gt;电脑App）&lt;/li&gt;
&lt;li&gt;Poster + PPT&lt;/li&gt;
&lt;li&gt;Presentation&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Deep Learning</title>
      <link>https://zhengzangw.com/notes/deep-learning/deep-learning/</link>
      <pubDate>Sun, 02 Sep 2018 00:00:00 +0000</pubDate>
      <author>zzw at smail.nju.edu.cn (Zangwei Zheng)</author>
      <guid>https://zhengzangw.com/notes/deep-learning/deep-learning/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Deep Learning&lt;/em&gt;
&lt;a href=&#34;https://www.bilibili.com/video/av9770302/?p=5&#34;&gt;李宏毅课程&lt;/a&gt;
&lt;a href=&#34;http://speech.ee.ntu.edu.tw/~tlkagk/courses_MLDS17.html&#34;&gt;李宏毅的主页&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;第六章&#34;&gt;第六章&lt;/h2&gt;
&lt;p&gt;Input -&amp;gt; FL -&amp;gt; FL -&amp;gt; FL -&amp;gt; Softmax -&amp;gt;&lt;/p&gt;
&lt;h3 id=&#34;输出单元&#34;&gt;输出单元&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;高斯输出分布线性单元&lt;/li&gt;
&lt;li&gt;Bernoulli输出分布sigmoid单元&lt;/li&gt;
&lt;li&gt;Multinoulli输出分布softmax单元&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Introuction to TensorFlow 1 Picture Handle</title>
      <link>https://zhengzangw.com/posts/tensorflow-picture/</link>
      <pubDate>Fri, 31 Aug 2018 00:00:00 +0000</pubDate>
      <author>zzw at smail.nju.edu.cn (Zangwei Zheng)</author>
      <guid>https://zhengzangw.com/posts/tensorflow-picture/</guid>
      <description>&lt;h1 id=&#34;图片的基础知识&#34;&gt;图片的基础知识&lt;/h1&gt;
&lt;p&gt;像素值只有 0，1： 二值图&lt;br&gt;
0-255：256 级灰度图&lt;br&gt;
图像位数通常是 8 位。简单可认为一张单通道 8 位彩色图有三通道 RGB&lt;br&gt;
转换为灰度公式很多，如：
$$Gray = R&lt;em&gt;30%+G&lt;/em&gt;59%+B*11%$$&lt;/p&gt;
&lt;h2 id=&#34;亮度&#34;&gt;亮度&lt;/h2&gt;
&lt;p&gt;RGB 颜色空间本身就是源于物体发光，每个通道上的值表示的是该通道上的光强，调整光强即是调整亮度。可以有如下公式：
$$亮度＝R&lt;em&gt;0.299+G&lt;/em&gt;0.587+B*0.114$$
$$l = (max(rgb) + min(rgb)) / 2$$&lt;/p&gt;
&lt;h2 id=&#34;对比度&#34;&gt;对比度&lt;/h2&gt;
&lt;p&gt;对比度反应了图片上亮区域和暗区域的层次感。而反应到图像编辑上，调整对比度就是在保证平均亮度不变的情况下，扩大或缩小亮的点和暗的点的差异&lt;/p&gt;
&lt;p&gt;$$Out = Average + (In – Average) * ( 1 + percent)$$&lt;/p&gt;
&lt;p&gt;其中 In 表示原始像素点亮度，Average 表示整张图片的平均亮度，Out 表示调整后的亮度，而 percent 即调整范围[-1,1]&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A toy experiments on Tensorflow 1</title>
      <link>https://zhengzangw.com/posts/tensorflow-experiment/</link>
      <pubDate>Tue, 28 Aug 2018 00:00:00 +0000</pubDate>
      <author>zzw at smail.nju.edu.cn (Zangwei Zheng)</author>
      <guid>https://zhengzangw.com/posts/tensorflow-experiment/</guid>
      <description>&lt;h1 id=&#34;前言&#34;&gt;前言&lt;/h1&gt;
&lt;p&gt;《深度学习》终于获得了“过半警告”，不过CNN,RNN都还没学。前面的很多算法都没有实践看过效果，决定在Tensorflow上实现一下。&lt;/p&gt;
&lt;p&gt;参考的资料有：《Tensorflow 实现Goolge深度学习框架》 莫烦的网络教程、&lt;/p&gt;
&lt;p&gt;这个系列尽可能做的好一点，加深对参数的理解和使用&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
